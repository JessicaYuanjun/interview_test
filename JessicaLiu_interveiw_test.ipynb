{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toronto Bike Stations\n",
    "#### Jessica Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline design and Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In consideration of the future run as daily, the pipeline was designed as follows. \n",
    "Imagine the entire process of processing Toronto Bike Station's data as an object, named as __TorontoBikeStation__. Based on this object, other pipeline components are designed,  including:\n",
    "- __Extract:__ used to extract the data from two APIs\n",
    "- __Transforming:__ used to merge and clean the data from Extract. Format it including rename,re-order, and re-type, based on the 'toronto_bike_stations' table.\n",
    "- __Loading:__ used to connect to the MS SQL Server and save the cleaned and formatted data to the database directly. (Specially designed for minutely status updates)\n",
    "- __TrigerFrequency:__ used to as a Timer. Start time, End time, interval, two URLs are as parameters. Used for cases like minutely status updates or daily updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract packages\n",
    "from urllib import request\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#Loading packages\n",
    "\n",
    "import pymssql \n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "#frequency packages\n",
    "from threading import Thread, Event\n",
    "import datetime    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract\n",
    "getAllColumns function is used to determine all attributes from each station. In station_status API, some records contain post_code, cross_street, or obcn, but some did not. To ensure we can get all features, I developed this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        \n",
    "        #consider the edge case (HTTP error, timeout, null value)\n",
    "        try:\n",
    "            req = request.Request(self.url)\n",
    "            with request.urlopen(req) as f:\n",
    "                data = json.loads(f.read().decode('utf-8'))\n",
    "        except:\n",
    "            print(\"HTTP Error or Timeout\")\n",
    "        else:\n",
    "            try:\n",
    "                len(data)<1\n",
    "            except:\n",
    "                print(\"empty json file\")\n",
    "            else:\n",
    "                                       \n",
    "                self.data = data\n",
    "                self.dic_list = data['data']['stations']\n",
    "                self.last_update=self.data['last_updated']\n",
    "    \n",
    "\n",
    "    def getAllColumns(self):\n",
    "        all_keys = []\n",
    "        for dic in self.dic_list:\n",
    "            keys = [str(key) for key in dic.keys()]\n",
    "            union_key = list(set(all_keys).union(set(keys)))\n",
    "            all_keys = union_key\n",
    "        return sorted(all_keys)\n",
    "\n",
    "    def getDataFrame(self):\n",
    "        # get the python data frame\n",
    "        dic_value = []\n",
    "        all_values = []\n",
    "        for dic in self.dic_list:\n",
    "            dic_value = [dic.get(key) for key in self.getAllColumns()]\n",
    "            all_values.append(dic_value)\n",
    "\n",
    "        result = pd.DataFrame(all_values, columns=self.getAllColumns())\n",
    "        result['last_updated'] = self.last_update\n",
    "        return result\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transforming:\n",
    "    def __init__(self,info_data,status_data):\n",
    "        self.info_data=info_data\n",
    "        self.status_data=pd.concat([status_data, status_data['num_bikes_available_types'].apply(pd.Series)], axis = 1).drop('num_bikes_available_types', axis = 1)\n",
    "        data=self.info_data.merge(self.status_data, how='outer', on='station_id') \n",
    "        self.data=data\n",
    "        \n",
    "\n",
    "\n",
    "    def cleanedData(self):\n",
    "        #rename to keep the same label as the database table columns name\n",
    "        data=self.data.rename(columns={\"lat\":\"latitude\",\"lon\":\"longitude\",\n",
    "                                              \"name\":\"station_name\",\n",
    "                                              \"mechanical\":\"mechanical_bikes_available\",\n",
    "                                              \"ebike\":\"electric_bikes_available\",\n",
    "                                              \"last_updated_x\":\"last_update\",\n",
    "                                              \"last_updated_y\":\"last_update_info\"})\n",
    "        #keeo the same order as the database table columns order\n",
    "        columnOrder=[\"last_update\",\"station_id\",\"station_name\",\"physical_configuration\",\n",
    "             \"latitude\",\"longitude\",\"altitude\",\"address\",\"capacity\",\"rental_methods\",\n",
    "             \"groups\",\"obcn\",\"nearby_distance\",\"num_bikes_available\",\n",
    "             \"mechanical_bikes_available\",\"electric_bikes_available\",\"num_bikes_disabled\",\n",
    "             \"num_docks_available\", \"num_docks_disabled\",\"is_installed\",\"is_renting\",\n",
    "             \"is_returning\", \"last_reported\",\"is_charging_station\", \"status\",\n",
    "             \"cross_street\",\"post_code\",\"last_update_info\"]\n",
    "        data=data[columnOrder]\n",
    "        \n",
    "        \n",
    "        #save all information \n",
    "        #station_result.to_csv('station_result.csv',header=True,index=False)\n",
    "          \n",
    "        \n",
    "        #drop out of service station and unuseful columns\n",
    "        data=data.drop(data[data['status']!='IN_SERVICE'].index)\n",
    "        cleaned_data=data.drop(columns=[\"cross_street\",\"post_code\",\"last_update_info\"])\n",
    "        \n",
    "        \n",
    "        #formate the data type \n",
    "        cleaned_data['last_update'] =  pd.to_datetime(cleaned_data['last_update'], unit='s')\n",
    "        cleaned_data['last_reported'] =  pd.to_datetime(cleaned_data['last_reported'], unit='s')\n",
    "        \n",
    "        cleaned_data[[\"station_id\",\"capacity\"]]=cleaned_data[[\"station_id\",\"capacity\"]].astype(int) \n",
    "        cleaned_data[[\"rental_methods\",\"groups\"]]=cleaned_data[[\"rental_methods\",\"groups\"]].astype(str)\n",
    "        cleaned_data[\"is_charging_station\"]=cleaned_data[\"is_charging_station\"].astype(int)\n",
    "        #data[[\"is_installed\",\"is_renting\",\"is_returning\"]]=data[[\"is_installed\",\"is_renting\",\"is_returning\"]].astype(bool)\n",
    "\n",
    "       #remove special characters \n",
    "        cleaned_data[\"rental_methods\"]=cleaned_data[\"rental_methods\"].str.strip('[]')\n",
    "        cleaned_data[\"groups\"]=cleaned_data[\"groups\"].str.strip('[]')\n",
    "        cleaned_data[\"groups\"]=cleaned_data[\"groups\"].str.replace(\"\\'\",\"\")\n",
    "        \n",
    "\n",
    "        return cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading\n",
    "May have pymssql install error on mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update  2 2020-10-13 07:18:07.068215\n"
     ]
    }
   ],
   "source": [
    "class Loading:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.conn = pymssql.connect(host='127.0.0.1:1433',user='sa',\n",
    "                       password='Mxl123ml',database='test',\n",
    "                      charset=\"utf8\")\n",
    "\n",
    "\n",
    "        self.engine = create_engine('mssql+pymssql://sa:Mxl123ml@127.0.0.1/test')\n",
    "\n",
    "    def loadData(self):\n",
    "        \n",
    "        return self.data.to_sql('test', self.engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorontoBikeStations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TonrontoBikeStations:\n",
    "    \n",
    "    def __init__(self, info_url,status_url):\n",
    "        self.info_url=info_url\n",
    "        self.status_url=status_url\n",
    "        info=Extract(self.info_url)\n",
    "        status=Extract(self.status_url)\n",
    "        self.info_data=info.getDataFrame()\n",
    "        self.status_data=status.getDataFrame() \n",
    "        trans=Transforming(self.info_data,self.status_data)\n",
    "        self.data=trans.cleanedData()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def saveToSQL(self):\n",
    "        load=Loading(self.data)\n",
    "        \n",
    "        return load.loadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrigerFrequency\n",
    "A timer, used to automatically run the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigerFrequency(Thread):\n",
    "\n",
    "    def __init__(self,start,stop,interval,info_url,status_url):\n",
    "        Thread.__init__(self)\n",
    "        self.event = Event()\n",
    "        self.runningTimes=((stop-start).seconds)/interval\n",
    "        self.interval=interval\n",
    "        self.info_url=info_url\n",
    "        self.status_url=status_url\n",
    "        \n",
    "\n",
    "    def run(self):\n",
    "        i=0\n",
    "        while not self.event.wait(self.interval):\n",
    "            i=i+1\n",
    "            toronto=TonrontoBikeStations(self.info_url,self.status_url)\n",
    "            print('Update ',i, datetime.datetime.now())\n",
    "            if i==self.runningTimes:\n",
    "                self.event.set()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          last_update  station_id                     station_name  \\\n",
      "0 2020-10-12 23:17:58        7000     Fort York  Blvd / Capreol Ct   \n",
      "1 2020-10-12 23:17:58        7001  Lower Jarvis St / The Esplanade   \n",
      "2 2020-10-12 23:17:58        7002       St. George St / Bloor St W   \n",
      "3 2020-10-12 23:17:58        7003         Madison Ave / Bloor St W   \n",
      "4 2020-10-12 23:17:58        7004          University Ave / Elm St   \n",
      "\n",
      "  physical_configuration   latitude  longitude  altitude  \\\n",
      "0                REGULAR  43.639832 -79.395954       0.0   \n",
      "1                REGULAR  43.647992 -79.370907       0.0   \n",
      "2                REGULAR  43.667333 -79.399429       0.0   \n",
      "3                REGULAR  43.667158 -79.402761       NaN   \n",
      "4                REGULAR  43.656518 -79.389099       NaN   \n",
      "\n",
      "                           address  capacity  \\\n",
      "0     Fort York  Blvd / Capreol Ct        35   \n",
      "1  Lower Jarvis St / The Esplanade        15   \n",
      "2       St. George St / Bloor St W        19   \n",
      "3         Madison Ave / Bloor St W        15   \n",
      "4          University Ave / Elm St        11   \n",
      "\n",
      "                                rental_methods  ... electric_bikes_available  \\\n",
      "0  'KEY', 'CREDITCARD', 'TRANSITCARD', 'PHONE'  ...                        0   \n",
      "1  'KEY', 'CREDITCARD', 'TRANSITCARD', 'PHONE'  ...                        1   \n",
      "2  'KEY', 'CREDITCARD', 'TRANSITCARD', 'PHONE'  ...                        0   \n",
      "3  'KEY', 'CREDITCARD', 'TRANSITCARD', 'PHONE'  ...                        0   \n",
      "4  'KEY', 'CREDITCARD', 'TRANSITCARD', 'PHONE'  ...                        0   \n",
      "\n",
      "  num_bikes_disabled  num_docks_available  num_docks_disabled  is_installed  \\\n",
      "0                  0                   16                   0             1   \n",
      "1                  1                    5                   0             1   \n",
      "2                  0                    8                   0             1   \n",
      "3                  0                    8                   0             1   \n",
      "4                  0                    7                   0             1   \n",
      "\n",
      "   is_renting  is_returning       last_reported  is_charging_station  \\\n",
      "0           1             1 2020-10-12 23:15:59                    0   \n",
      "1           1             1 2020-10-12 23:15:44                    0   \n",
      "2           1             1 2020-10-12 23:17:47                    0   \n",
      "3           1             1 2020-10-12 23:16:35                    0   \n",
      "4           1             1 2020-10-12 23:14:10                    0   \n",
      "\n",
      "       status  \n",
      "0  IN_SERVICE  \n",
      "1  IN_SERVICE  \n",
      "2  IN_SERVICE  \n",
      "3  IN_SERVICE  \n",
      "4  IN_SERVICE  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "info_url = 'https://tor.publicbikesystem.net/ube/gbfs/v1/en/station_information'\n",
    "status_url = 'https://tor.publicbikesystem.net/ube/gbfs/v1/en/station_status'\n",
    "\n",
    "toronto=TonrontoBikeStations(info_url,status_url)\n",
    "\n",
    "data=toronto.data\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "data.to_csv('final_result.csv',header=True,index=False)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triger Frequency Test\n",
    "##### Assume the start time is now and stop time is 1 min later, get information every 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_url = 'https://tor.publicbikesystem.net/ube/gbfs/v1/en/station_information'\n",
    "status_url = 'https://tor.publicbikesystem.net/ube/gbfs/v1/en/station_status'\n",
    "\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "stop = start + datetime.timedelta(seconds=60)\n",
    "    \n",
    "timer_test = TrigerFrequency(start,stop,10,info_url,status_url)\n",
    "timer_test.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "</br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA test script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QATest():\n",
    "    \n",
    "    def __init__(self,info_url,status_url):\n",
    "        self.info_url=info_url\n",
    "        self.status_url=status_url\n",
    "        self.info=Extract(self.info_url)\n",
    "        self.status=Extract(self.status_url)\n",
    "        trans=Transforming(self.info.getDataFrame(),self.status.getDataFrame())\n",
    "        self.cleaned_data=trans.cleanedData()\n",
    "        \n",
    "        \n",
    "      \n",
    "    \n",
    "    #test Extract class:\n",
    "    #if the API's json structure are still the same\n",
    "    def jsonStructure(self):\n",
    "           # ensure loaded json is dictonary \n",
    "        if type(self.info.data) != dict:\n",
    "            print(\"wrong info json format\")\n",
    "        if type(self.status.data) != dict:\n",
    "            print(\"wrong status json format\")\n",
    "            \n",
    "        # ensure it contains 'last_updated' field                             \n",
    "        if 'last_updated'not in self.info.data:\n",
    "            print(\"no info updated date\")\n",
    "        if 'last_updated'not in self.status.data:\n",
    "            print(\"no info status date\")\n",
    "            \n",
    "        # ensure 'data' is exist   \n",
    "        if 'data'not in self.info.data:\n",
    "            print(\"no data\")\n",
    "        if 'data'not in self.status.data:\n",
    "            print(\"no data\")\n",
    "            \n",
    "        # ensure 'data' contains records                \n",
    "        if len(self.info.dic_list)==0:            \n",
    "            print(\"info API is empty\")\n",
    "        if len(self.status.dic_list)==0:\n",
    "            print(\"info API is empty\")\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    #test Transforming class:\n",
    "    def formattedData(self):\n",
    "        tras=Transforming(self.info.getDataFrame(),self.status.getDataFrame())\n",
    "        \n",
    "        \n",
    "        # ensure no dupilicate in the key attribute 'station_id' \n",
    "        dic={}.fromkeys(tras.data['station_id'])\n",
    "        if len(dic)!=len(tras.data['station_id']):\n",
    "            print('There is dupilicate station_id')\n",
    "            \n",
    "        # ensure get all feature\n",
    "        if tras.data.shape[1]!=28:\n",
    "            print('Did not extract all features')\n",
    "                    \n",
    "        # ensure cleaned DataFrame contains all requried attributes\n",
    "        if tras.cleanedData().shape[1]!=25:\n",
    "            print(\"Attibutes did not consistent with 'toronto_bike_stations' attributes\")\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    #test if connect to the database\n",
    "    def connectDatabase(self):\n",
    "        connect=Loading(self.cleaned_data)\n",
    "        \n",
    "        conn=connect.conn\n",
    "        cursor = conn.cursor()\n",
    "        sql = 'select top 2 * from sql_test'\n",
    "        cursor.execute(sql)\n",
    "        rs = cursor.fetchall()\n",
    "        print(rs)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2020-10-12 22:43:44.0000000', 7000, 'Fort York  Blvd / Capreol Ct', 'REGULAR', 43.639832, -79.395954, 0.0, 'Fort York  Blvd / Capreol Ct', 35, \"'KEY', 'CREDITCARD', 'TRANSITCARD', 'PHONE'\", None, '647-643-9607', 500.0, '21', '20', '1', '0', '14', '0', '1', '1', '1', '2020-10-12 22:39:43.0000000', '0', 'IN_SERVICE'), ('2020-10-12 22:43:44.0000000', 7001, 'Lower Jarvis St / The Esplanade', 'REGULAR', 43.647992, -79.370907, 0.0, 'Lower Jarvis St / The Esplanade', 15, \"'KEY', 'CREDITCARD', 'TRANSITCARD', 'PHONE'\", None, '416-617-9576', 500.0, '7', '7', '0', '1', '7', '0', '1', '1', '1', '2020-10-12 22:39:33.0000000', '0', 'IN_SERVICE')]\n"
     ]
    }
   ],
   "source": [
    "#test code\n",
    "info_url = 'https://tor.publicbikesystem.net/ube/gbfs/v1/en/station_information'\n",
    "status_url = 'https://tor.publicbikesystem.net/ube/gbfs/v1/en/station_status'\n",
    "   \n",
    "test=QATest(info_url,status_url)\n",
    "test.jsonStructure()\n",
    "test.formattedData()\n",
    "test.connectDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the closest five bike stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     station_id                                 station_name         dis\n",
      "66         7066                 Willcocks St / St. George St  128.426129\n",
      "326        7358  Gailbraith Rd / King’s College Cr. (U of T)  179.106283\n",
      "229        7250           St. George St / Russell St - SMART  193.535201\n",
      "544        7600                Russell St / Huron St - SMART  235.838132\n",
      "177        7190                   St. George St / Hoskin Ave  255.980827\n"
     ]
    }
   ],
   "source": [
    "from math import sin, asin, cos, radians, fabs, sqrt\n",
    "\n",
    "def distance(lon1, lat1, lon2, lat2): \n",
    "    # Convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    " \n",
    "    # distance\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # The average radius of the earth, in kilometers\n",
    "    return c * r * 1000\n",
    "\n",
    "\n",
    "\n",
    "dis_data=data.loc[:,['station_id','station_name','address','latitude','longitude']]\n",
    "\n",
    "dis=[]\n",
    "for i in range(len(dis_data)):\n",
    "    dis.append(distance(-79.396160,43.661896,dis_data['longitude'][i],dis_data['latitude'][i]))    \n",
    "\n",
    "dis_data['dis']=dis\n",
    "#ordered data by distance\n",
    "ordered_dis=dis_data.sort_values(by=['dis'])\n",
    "\n",
    "print(ordered_dis[['station_id','station_name','dis']].head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
